{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Example: MNIST\n",
    "\n",
    "Fully-connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**出力ログ制御**  \n",
    "\n",
    "定数のサンプル実行時はログがたくさん出てきたので、今回は出力するログにフィルタを掛けました。\n",
    "フィルタを掛けるにはos.environ['TF_CPP_MIN_LOG_LEVEL']を使用します。\n",
    "\n",
    " - 0:　すべて\n",
    " - 1:　警告、エラー\n",
    " - 2:　エラー\n",
    " - 3:　でない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset():\n",
    "    (x_train,y_train),_ = datasets.mnist.load_data() \n",
    "    ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    ds = ds.map(prepare_mnist_features_and_labels)\n",
    "    ds = ds.take(20000).shuffle(20000).batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mnist_features_and_labels(x, y):\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(10)])\n",
    "\n",
    "optimizer = optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data and model set up, we can start setting up the training procedure. For the methods here, we use the @tf.function AutoGraph decorator to pre-compile our methods as TensorFlow computational graphs. TensorFlow 2.0 is fully imperative, so the AutoGraph decorator isn't necessary for our code to work, but it speeds up execution and lets us take advantage of graph execution, so @tf.function is definitely worth using in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss(logits, labels):\n",
    "    return tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=labels))\n",
    "\n",
    "@tf.function\n",
    "def compute_accuracy(logits, labels):\n",
    "    predictions = tf.argmax(logits, axis=1)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(predictions, labels), tf.float32))\n",
    "\n",
    "@tf.function\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss = compute_loss(logits, y)\n",
    "\n",
    "    # compute gradient\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    # update to weights\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "\n",
    "    # loss and accuracy is scalar tensor\n",
    "    return loss, accuracy\n",
    "\n",
    "def train(epoch, model, optimizer):\n",
    "\n",
    "    train_ds = mnist_dataset()\n",
    "    loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for step, (x, y) in enumerate(train_ds):\n",
    "        loss, accuracy = train_one_step(model, optimizer, x, y)\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            print('epoch', epoch, ': loss', loss.numpy(), '; accuracy', accuracy.numpy())\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28), (None,)), types: (tf.uint8, tf.uint8)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
