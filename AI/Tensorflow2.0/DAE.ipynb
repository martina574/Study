{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparations\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "np.random.seed(222)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Const def\n",
    "batch_size = 128\n",
    "h_size = 10\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "## Save 10 images\n",
    "def save_images(images, name):\n",
    "    new_img = np.zeros((320,100,3), dtype=np.float32)\n",
    "    idx = 0\n",
    "    for i in range(0, 320, 32):\n",
    "        im_o = images[idx]\n",
    "        im_n = images[idx+batch_size]\n",
    "        new_img[i:i+32,0:32] = im_o.copy()\n",
    "        new_img[i:i+32,50:82] = im_n.copy()\n",
    "    new_img = new_img.clip(0,255).astype(np.uint8)\n",
    "    cv2.imwrite(name, new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "## Load data to memory\n",
    "db = tf.keras.datasets.cifar10\n",
    "(_x, y), (_xt, yt) = db.load_data()\n",
    "in_shape = _x.shape\n",
    "o_shape = y.shape\n",
    "print(in_shape, o_shape)\n",
    "## Regualizatiom\n",
    "x, xt = _x.astype(np.float32)/255., _xt.astype(np.float32)/255.\n",
    "## Create dateset\n",
    "train_x = tf.data.Dataset.from_tensor_slices(x)\n",
    "train_x = train_x.shuffle(2000).batch(batch_size)\n",
    "test_x = tf.data.Dataset.from_tensor_slices(xt)\n",
    "test_x = test_x.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAE(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DAE, self).__init__()\n",
    "        \n",
    "        self.conv = tf.keras.layers.Conv2D(32, (3,3), padding='same', strides=1)\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.nn.relu()\n",
    "        \n",
    "        self.block = tf.keras.Sequential()\n",
    "        self.block.add(self.conv)\n",
    "        self.block.add(self.bn)\n",
    "        self.block.add(relu)\n",
    "        \n",
    "        self.encoder_layer = tf.keras.Sequential()\n",
    "        self.encoder_layer(tf.keras.layers.UpSampling2D((2,2)))\n",
    "        self.encoder_layer(self.block)\n",
    "        \n",
    "        self.decoder_layer = tf.keras.Sequential()\n",
    "        self.decoder_layer.add(tf.keras.layers.MaxPool2D((2,2)))\n",
    "        self.decoder_layer.add(self.block)\n",
    "        \n",
    "        self.encoder = tf.keras.Sequential()\n",
    "        self.encoder.add(encoder_layer)\n",
    "        self.encoder.add(encoder_layer)\n",
    "        self.encoder\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        h = self.encoder(inputs)\n",
    "        x_ = self.decoder(h)\n",
    "        \n",
    "        return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dae_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_10 (Sequential)   (None, 10)                3844682   \n",
      "_________________________________________________________________\n",
      "sequential_11 (Sequential)   (None, 3072)              3847744   \n",
      "=================================================================\n",
      "Total params: 7,692,426\n",
      "Trainable params: 7,692,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = DAE()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.5978628993034363\n",
      "0 200 0.5973314046859741\n",
      "1 0 0.6093522310256958\n",
      "1 200 0.5990936160087585\n",
      "2 0 0.599271297454834\n",
      "2 200 0.6011543869972229\n",
      "3 0 0.5994608402252197\n",
      "3 200 0.5955417156219482\n",
      "4 0 0.6054425835609436\n",
      "4 200 0.5852481126785278\n",
      "5 0 0.593393087387085\n",
      "5 200 0.6010866761207581\n",
      "6 0 0.5944775342941284\n",
      "6 200 0.6061115264892578\n",
      "7 0 0.6002156734466553\n",
      "7 200 0.5908162593841553\n",
      "8 0 0.5991817712783813\n",
      "8 200 0.5983622074127197\n",
      "9 0 0.6012532711029053\n",
      "9 200 0.5996942520141602\n",
      "10 0 0.6023633480072021\n",
      "10 200 0.5912548899650574\n",
      "11 0 0.599865198135376\n",
      "11 200 0.5971051454544067\n",
      "12 0 0.5959611535072327\n",
      "12 200 0.5939546823501587\n",
      "13 0 0.6047912240028381\n",
      "13 200 0.5931234359741211\n",
      "14 0 0.6033704876899719\n",
      "14 200 0.5980308651924133\n",
      "15 0 0.6040289998054504\n",
      "15 200 0.5934886932373047\n",
      "16 0 0.5922679305076599\n",
      "16 200 0.595300555229187\n",
      "17 0 0.5968851447105408\n",
      "17 200 0.5943707227706909\n",
      "18 0 0.5974487662315369\n",
      "18 200 0.5859962105751038\n",
      "19 0 0.6001567840576172\n",
      "19 200 0.5819618105888367\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "optimizer = tf.optimizers.Adam(lr=learning_rate)\n",
    "for epoch in range(20):\n",
    "    for step, x in enumerate(train_x):\n",
    "        x=tf.reshape(x, [-1, 32*32*3])\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            x_logits = model(x)\n",
    "            rec_loss = tf.losses.binary_crossentropy(x, x_logits, from_logits=True)\n",
    "            rec_loss = tf.reduce_mean(rec_loss)\n",
    "        grad = tape.gradient(rec_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print(epoch, step, float(rec_loss))\n",
    "            \n",
    "    # Evaluation\n",
    "    x = next(iter(test_x))\n",
    "    x_flat = tf.reshape(x, [-1, 32*32*3])\n",
    "    logits = model(x_flat)\n",
    "    x_ = tf.sigmoid(logits)\n",
    "    x_img = tf.reshape(x_, [-1, 32, 32, 3])\n",
    "    \n",
    "    # Concate original img & new img to compare\n",
    "    x_toshow = tf.concat([x, x_img], axis=0)\n",
    "    #cv2.imshow(x)\n",
    "    \n",
    "    x_toshow = x_toshow.numpy() * 255. \n",
    "    x_toshow = x_toshow.astype(np.uint8)\n",
    "    save_images(x_toshow, 'Tmp/Result_%d.jpg'%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
